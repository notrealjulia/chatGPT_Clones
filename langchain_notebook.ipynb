{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain   \n",
    "\n",
    "## 1. Chains\n",
    "Chains in LangChain are sequences of components that process language input and generate responses. These components can be simple functions, calls to language models, or more complex operations such as database queries or API calls. The idea is to chain these components together to form a pipeline that handles the entire process of understanding, processing, and responding to user inputs.\n",
    "\n",
    "__Types of Chains__:  \n",
    "__Linear Chains__: Execute a sequence of tasks one after another, where the output of one component is the input to the next.  \n",
    "__Branching Chains__: Allow for conditional execution paths depending on the input or the outcomes of previous tasks in the chain.  \n",
    "__Looping Chains__: Enable repeating a set of tasks until a certain condition is met, useful for refining answers or gathering additional information.  \n",
    "\n",
    "https://python.langchain.com/docs/modules/chains/\n",
    "\n",
    "## 2. Agents\n",
    "Agents in LangChain are entities that manage the interaction between the user and the system. An agent coordinates the chains, decides which one to invoke based on the context or the nature of the query, and manages state across interactions. This is crucial for maintaining the continuity in conversations, especially in applications like chatbots or virtual assistants.\n",
    "\n",
    "__Key Features of Agents__:\n",
    "__Context Management__: Agents maintain a conversational context, remembering past interactions and using this context to make decisions about future interactions.  \n",
    "__Stateful Logic__: They can manage stateful interactions, which are essential for tasks that require an understanding of the conversation history to provide relevant responses.  \n",
    "__Modularity__: Agents are designed to be modular, so developers can swap out components or chains as needed without redesigning the entire system.  \n",
    "\n",
    "https://python.langchain.com/docs/modules/agents/\n",
    "## 3. Retrieval Strategies\n",
    "Retrieval strategies in LangChain define how the system retrieves information needed to answer queries or perform tasks. This is particularly important when the system needs to pull in external information from databases, APIs, or through search queries.\n",
    "\n",
    "__Examples of Retrieval Strategies__:  \n",
    "__Document Retrieval__: Fetching relevant documents or content from a database or a set of files based on the query.  \n",
    "__API Retrieval__: Making API calls to external services to retrieve data or perform actions relevant to the user’s request.  \n",
    "__Search-Augmented Models__: Integrating search results into the processing chain to enhance the model’s responses with up-to-date or specific information not contained within the model’s training data.  \n",
    "### Integration and Operation\n",
    "In LangChain, these components are integrated into a cohesive system where agents use chains to handle user inputs, applying appropriate retrieval strategies as needed. The system is designed to be flexible and scalable, allowing developers to customize each component according to their specific requirements.\n",
    "\n",
    "### For example, a LangChain application for customer support might use:\n",
    "\n",
    "A chain that includes components for greeting users, understanding their problems, and retrieving solutions from a knowledge base.  \n",
    "An agent that manages these chains, deciding when to escalate an issue to a human based on the complexity of the problem.  \n",
    "A retrieval strategy that pulls information from both a FAQ database and real-time product data to provide accurate and relevant responses.  \n",
    "This architecture allows LangChain to be both powerful and adaptable, making it an excellent choice for developers looking to build advanced language-driven applications.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL QUERY CHAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -U langchain langchain-community langchain-openai\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import create_sql_query_chain\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "import streamlit as st\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "link to the dataset https://www.sqlitetutorial.net/sqlite-sample-database/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['albums', 'artists', 'customers', 'employees', 'genres', 'invoice_items', 'invoices', 'media_types', 'playlist_track', 'playlists', 'tracks']\n"
     ]
    }
   ],
   "source": [
    "db = SQLDatabase.from_uri(\"sqlite:///Chinook.db\")\n",
    "print(db.get_usable_table_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT \"EmployeeId\", \"LastName\", \"FirstName\", \"Title\"\n",
      "FROM employees\n",
      "[(1, 'Adams', 'Andrew', 'General Manager'), (2, 'Edwards', 'Nancy', 'Sales Manager'), (3, 'Peacock', 'Jane', 'Sales Support Agent'), (4, 'Park', 'Margaret', 'Sales Support Agent'), (5, 'Johnson', 'Steve', 'Sales Support Agent'), (6, 'Mitchell', 'Michael', 'IT Manager'), (7, 'King', 'Robert', 'IT Staff'), (8, 'Callahan', 'Laura', 'IT Staff')]\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", api_key=st.secrets[\"OPENAI_API_KEY\"])\n",
    "chain = create_sql_query_chain(llm, db)\n",
    "generated_sql_query = chain.invoke({\"question\": \"Who are all my employees?\"})\n",
    "print(generated_sql_query)\n",
    "answer = db.run(generated_sql_query)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "type(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_query(question):\n",
    "    \"\"\"\n",
    "    Executes a generated SQL query based on the provided question.\n",
    "\n",
    "    Parameters:\n",
    "    question (str): The natural language question from which to generate an SQL query.\n",
    "\n",
    "    Returns:\n",
    "    list: The result of the SQL query.\n",
    "    \"\"\"\n",
    "    # Ensure that the chain and the necessary components are correctly initialized\n",
    "    chain = create_sql_query_chain(llm, db)\n",
    "    \n",
    "    # Invoke the chain to generate an SQL query\n",
    "    generated_sql_query = chain.invoke({\"question\": question})\n",
    "    \n",
    "     # Execute the generated SQL query\n",
    "    query_results = db.run(generated_sql_query)\n",
    "\n",
    "    # This part is annoying, because the query results are returned as a string, even though it looks like a list, so we make it a list\n",
    "    query_results = ast.literal_eval(query_results)\n",
    "\n",
    "    # Convert the query results (typically a list of tuples) to a string\n",
    "    # Assuming each tuple is a row of results\n",
    "    if query_results:\n",
    "        # Format each row as a string and then join all rows with a newline\n",
    "        result_str = [\" \".join(map(str, item)) for item in query_results]\n",
    "    else:\n",
    "        result_str = \"No results found.\"\n",
    "\n",
    "    return result_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1 Adams Andrew', '2 Edwards Nancy', '3 Peacock Jane', '4 Park Margaret', '5 Johnson Steve', '6 Mitchell Michael', '7 King Robert', '8 Callahan Laura']\n"
     ]
    }
   ],
   "source": [
    "print(execute_query(\"Who are all my employees?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rock 1297', 'Latin 579', 'Metal 374', 'Alternative & Punk 332', 'Jazz 130']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execute_query(\"Where are the top 5 most popular genres?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5.65']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execute_query(\"How much does the average customer spend? Round up the answer to two decimal points.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
